<!-- This comment will put IE 6, 7 and 8 in quirks mode -->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>ReClaM: DF_CrossEntropy Class Reference</title>
<script type="text/javaScript" src="search/search.js"></script>
<link href="../css/main.css" rel="stylesheet" type="text/css"/>
</head>
<body id="type-b">

<div id="wrap">
<div id="header">
<div id="site-name">Shark Machine Learning Library</div>
<div id="poweredby">
<img style="width: 95%;" src="../images/SharkLogo.png"/>
</div>		
  
<ul id="nav">
  <li class="first"><a href="../index.html">About Shark</a></li>
  <li><a href="#">Sourceforge</a>
  
  <ul>
    <li class="first"><a href="http://shark-project.sourceforge.net">Project Summary</a></li>
    <li><a href="http://sourceforge.net/projects/shark-project/files/">Downloads</a></li>
    <li><a href="http://sourceforge.net/projects/shark-project/develop">Subversion Repository</a></li>
  </ul>
  
</li>
<li class="first"><a href="../GettingStarted.html">Getting Started</a>
<li class="first"><a href="../Tutorials.html">Tutorials</a>
<li class="first"><a href="../FAQ.html">FAQ</a>

<li class="first"><a href="#">Main Modules</a>
<ul>
  <li class="first"><a href="../ReClaM/index.html">ReClaM</a>
  <li class="first"><a href="../EALib/index.html">EALib</a>
  <li class="first"><a href="../MOO-EALib/index.html">MOO-EALib</a>
  <li class="first"><a href="../Fuzzy/index.html">Fuzzy</a>
</ul>
</li>
<li class="first"><a href="#">Tools</a>
<ul>
  <li class="first"><a href="../Mixture/index.html">Mixture</a>
  <li><a href="../Array/index.html">Array</a>
  <li><a href="../Rng/index.html">Rng</a>
  <li><a href="../LinAlg/index.html">LinAlg</a>
  <li class="last"><a href="../FileUtil/index.html">FileUtil</a>		    
</ul>
</li>
</ul>
</div>

<!--<div id="header">
<div id="site-name">Shark Machine Learning Library</div>
  <ul id="nav">
    <li><a href="../index.html"><span>Shark&nbsp;Main&nbsp;Page</span></a></li>
    <li><a href="../Array/index.html"><span>Array</span></a></li>
    <li><a href="../Rng/index.html"><span>Rng</span></a></li>
    <li><a href="../LinAlg/index.html"><span>LinAlg</span></a></li>
    <li><a href="../FileUtil/index.html"><span>FileUtil</span></a></li>
    <li><a href="../EALib/index.html"><span>EALib</span></a></li>
    <li><a href="../MOO-EALib/index.html"><span>MOO-EALib</span></a></li>
    <li class="active"><a href="../ReClaM/index.html"><span>ReClaM</span></a></li>
    <li><a href="../Fuzzy/index.html"><span>Fuzzy</span></a></li>
    <li><a href="../Mixture/index.html"><span>Mixture</span></a></li>
    <li><a href="../tutorials/index.html"><span>Tutorials</span></a></li>
    <li><a href="../faq/index.html"><span>FAQ</span></a></li>
  </ul>
 </div> -->
<!-- Generated by Doxygen 1.7.3 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="hierarchy.html"><span>Class&#160;Hierarchy</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a>  </div>
  <div class="headertitle">
<h1>DF_CrossEntropy Class Reference</h1>  </div>
</div>
<div class="contents">
<!-- doxytag: class="DF_CrossEntropy" --><!-- doxytag: inherits="ErrorFunction" -->
<p>Error measure for classication tasks that can be used as the objective function for training.  
<a href="#_details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_d_f___cross_entropy_8h_source.html">DF_CrossEntropy.h</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for DF_CrossEntropy:</div>
<div class="dyncontent">
 <div class="center">
  <img src="class_d_f___cross_entropy.png" usemap="#DF_CrossEntropy_map" alt=""/>
  <map id="DF_CrossEntropy_map" name="DF_CrossEntropy_map">
<area href="class_error_function.html" alt="ErrorFunction" shape="rect" coords="0,0,113,24"/>
</map>
 </div></div>

<p><a href="class_d_f___cross_entropy-members.html">List of all members.</a></p>
<table class="memberdecls">
<tr><td colspan="2"><h2><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_d_f___cross_entropy.html#aa0fc1e9f8f0b0d1112e2bd87efbfe290">error</a> (<a class="el" href="class_model.html">Model</a> &amp;model, const Array&lt; double &gt; &amp;input, const Array&lt; double &gt; &amp;target)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculates the cross entropy error.  <a href="#aa0fc1e9f8f0b0d1112e2bd87efbfe290"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_d_f___cross_entropy.html#a19aaa74b6b3c27b9a5e6a7ed7924e342">errorDerivative</a> (<a class="el" href="class_model.html">Model</a> &amp;model, const Array&lt; double &gt; &amp;input, const Array&lt; double &gt; &amp;target, Array&lt; double &gt; &amp;derivative)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculates the derivatives of the cross entropy error (see <a class="el" href="class_d_f___cross_entropy.html#aa0fc1e9f8f0b0d1112e2bd87efbfe290" title="Calculates the cross entropy error.">error</a>) with respect to the parameters ErrorFunction::w.  <a href="#a19aaa74b6b3c27b9a5e6a7ed7924e342"></a><br/></td></tr>
</table>
<hr/><a name="_details"></a><h2>Detailed Description</h2>
<div class="textblock"><p>Error measure for classication tasks that can be used as the objective function for training. </p>
<p>If your model should return a vector whose components are reflecting the class conditonal probabilities of class membership given any input vector 'DF_CrossEntropy' is the adequate error measure for model-training. For <em>C&gt;1</em>, dimension of model's output and every output dimension represents the probability for class membership of the given input vector, the error measure applied is defined as </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ E = - \sum_{i=1}^N \sum_{k=1}^C \left\{target^i_k \cdot\ln \frac{\exp{(model_k(input^i))}} {\sum_{k^{\prime}=1}^C \exp{(model_{k^{\prime}}(input^i))}} \right\} \]" src="form_159.png"/>
</p>
<p> where <em>i</em> runs over all input patterns and every term in the sum equals zero if the coefficient equals zero, since <em>x</em> <em>ln(x)</em> is zero in limes of x running to zero. The argument of the logarithm calculates the so called softmax-activation to guarantee for unity at the outputs, i.e. </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \sum_{k=1}^C \frac{\exp{(model_k(input^i))}}{\sum_{k^{\prime}=1}^C \exp{(model_{k^{\prime}}(input^i))}} = 1 \]" src="form_160.png"/>
</p>
<p> This is neccessary in order to interprete the output values as probabilities. This error functional can be derivated and so used for training. In case of only one single output dimension 'DF_CrossEntropy' returns the corresponding cross entropy for two classes, using the formalism </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ E = - \sum_{i=1}^N \left\{target^i\cdot \ln model(input^i) + (1-target^i) \cdot\ln (1-model(input^i))\right\} \]" src="form_161.png"/>
</p>
<p>In this implementation every target value has to be chosen from {0,1} (binary encoding). For theoretical reasons it is suggested to use for neural networks with one output neuron the logistic sigmoid activation function at the output. For multiple outputs it's required to use linear activiation, since this error implementation transforms the linear output to the softmax activiation as described above. For detailed information refer to (C.M. Bishop, Neural Networks for Pattern Recognition, Clarendon Press 1996, Chapter 6.9.)</p>
<p>This implementation of the cross entropy performs more efficient than the implemetation given in 'CrossEntropy.h' for more than one output dimensions, because redundant calculations of the outer derivatives are circumvented.</p>
<dl class="user"><dt><b>Status:</b></dt><dd>stable </dd></dl>

<p>Definition at line <a class="el" href="_d_f___cross_entropy_8h_source.html#l00098">98</a> of file <a class="el" href="_d_f___cross_entropy_8h_source.html">DF_CrossEntropy.h</a>.</p>
</div><hr/><h2>Member Function Documentation</h2>
<a class="anchor" id="aa0fc1e9f8f0b0d1112e2bd87efbfe290"></a><!-- doxytag: member="DF_CrossEntropy::error" ref="aa0fc1e9f8f0b0d1112e2bd87efbfe290" args="(Model &amp;model, const Array&lt; double &gt; &amp;input, const Array&lt; double &gt; &amp;target)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double DF_CrossEntropy::error </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_model.html">Model</a> &amp;&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>target</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td><code> [inline, virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Calculates the cross entropy error. </p>
<p>The cross entropy function for <em>N</em> patterns and <em>C&gt;1</em> class-dimensions within the output vector is calculated via </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ E = - \sum_{i=1}^N \sum_{k=1}^C \left\{target^i_k\cdot \ln \frac{\exp{(model_k(input^i))}} {\sum_{k^{\prime}=1}^C \exp{(model_{k^{\prime}}(input^i))}}\right\} \]" src="form_162.png"/>
</p>
<p> respectively for only one single output dimension and two classes via </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ E = - \sum_{i=1}^N \left\{target^i\cdot \ln model(input^i) + (1-target^i) \ln (1-model(input^i))\right\} \]" src="form_163.png"/>
</p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>the model. </td></tr>
    <tr><td class="paramname">input</td><td>Input vector for the model. </td></tr>
    <tr><td class="paramname">target</td><td>Target vector. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd>The error <em>E</em>.</dd></dl>
<dl class="author"><dt><b>Author:</b></dt><dd>M. Huesken </dd></dl>
<dl class="date"><dt><b>Date:</b></dt><dd>1999</dd></dl>
<dl class="user"><dt><b>Changes</b></dt><dd>Revision 2003/06/03 (S. Wiegand): softmax activation introduced</dd></dl>
<dl class="user"><dt><b>Status</b></dt><dd>stable </dd></dl>

<p>Implements <a class="el" href="class_error_function.html#a116fe3002d98786b63ccc5f1a480ac14">ErrorFunction</a>.</p>

<p>Definition at line <a class="el" href="_d_f___cross_entropy_8h_source.html#l00138">138</a> of file <a class="el" href="_d_f___cross_entropy_8h_source.html">DF_CrossEntropy.h</a>.</p>

<p>References <a class="el" href="_model_8h_source.html#l00336">Model::getOutputDimension()</a>, and <a class="el" href="class_model.html#acc59c7d4e90e91083b86f0834eb603d9">Model::model()</a>.</p>

</div>
</div>
<a class="anchor" id="a19aaa74b6b3c27b9a5e6a7ed7924e342"></a><!-- doxytag: member="DF_CrossEntropy::errorDerivative" ref="a19aaa74b6b3c27b9a5e6a7ed7924e342" args="(Model &amp;model, const Array&lt; double &gt; &amp;input, const Array&lt; double &gt; &amp;target, Array&lt; double &gt; &amp;derivative)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double DF_CrossEntropy::errorDerivative </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_model.html">Model</a> &amp;&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>target</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Array&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>derivative</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td><code> [inline, virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Calculates the derivatives of the cross entropy error (see <a class="el" href="class_d_f___cross_entropy.html#aa0fc1e9f8f0b0d1112e2bd87efbfe290" title="Calculates the cross entropy error.">error</a>) with respect to the parameters ErrorFunction::w. </p>
<p>The derivatives of the cross entropy for <em>N</em> patterns and <em>C&gt;1</em> class-dimensions within the output vector with respect to model parameters <em>w</em> are calculated via </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \frac{\partial E}{\partial w} = - \sum_{i=1}^N \sum_{k=1}^C \left\{ \left(target^i_k - \frac{\exp{(model_k(in^i))}}{\sum_{k^{\prime}=1}^C \exp{(model_{k^{\prime}}(input^i))}} \right) \cdot\frac{\partial model_k(input^i)}{\partial w}\right\} \]" src="form_164.png"/>
</p>
<p> respectively for only one single output dimension via </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \frac{\partial E}{\partial w} = - \sum_{i=1}^N \left\{ \frac{target^i - .model(input^i)}{model(input^i)\cdot(1-model(input^i))} \cdot\frac{\partial model(input^i)}{\partial w}\right\} \]" src="form_165.png"/>
</p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>the model. </td></tr>
    <tr><td class="paramname">input</td><td>Input vector for the model. </td></tr>
    <tr><td class="paramname">target</td><td>Target vector. </td></tr>
    <tr><td class="paramname">derivative</td><td>error derivative</td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd>The cross entropy error</dd></dl>
<dl class="author"><dt><b>Author:</b></dt><dd>M. Huesken </dd></dl>
<dl class="date"><dt><b>Date:</b></dt><dd>1999</dd></dl>
<dl class="user"><dt><b>Changes</b></dt><dd>Revision 2003/06/03 (S. Wiegand): softmax activation introduced, bugs in calculation of derivatives corrected</dd></dl>
<dl class="user"><dt><b>Status</b></dt><dd>stable </dd></dl>

<p>Reimplemented from <a class="el" href="class_error_function.html#a1d7581c61746f51aa96f74fc17a30d55">ErrorFunction</a>.</p>

<p>Definition at line <a class="el" href="_d_f___cross_entropy_8h_source.html#l00250">250</a> of file <a class="el" href="_d_f___cross_entropy_8h_source.html">DF_CrossEntropy.h</a>.</p>

<p>References <a class="el" href="_model_8cpp_source.html#l00088">Model::generalDerivative()</a>, <a class="el" href="_model_8h_source.html#l00336">Model::getOutputDimension()</a>, <a class="el" href="_model_8h_source.html#l00343">Model::getParameterDimension()</a>, and <a class="el" href="class_model.html#acc59c7d4e90e91083b86f0834eb603d9">Model::model()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li><a class="el" href="_d_f___cross_entropy_8h_source.html">DF_CrossEntropy.h</a></li>
</ul>
</div>
</div>
</div>
</body></html>
