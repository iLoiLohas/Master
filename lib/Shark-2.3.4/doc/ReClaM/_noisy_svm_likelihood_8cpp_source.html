<!-- This comment will put IE 6, 7 and 8 in quirks mode -->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>ReClaM: NoisySvmLikelihood.cpp Source File</title>
<script type="text/javaScript" src="search/search.js"></script>
<link href="../css/main.css" rel="stylesheet" type="text/css"/>
</head>
<body id="type-b">

<div id="wrap">
<div id="header">
<div id="site-name">Shark Machine Learning Library</div>
<div id="poweredby">
<img style="width: 95%;" src="../images/SharkLogo.png"/>
</div>		
  
<ul id="nav">
  <li class="first"><a href="../index.html">About Shark</a></li>
  <li><a href="#">Sourceforge</a>
  
  <ul>
    <li class="first"><a href="http://shark-project.sourceforge.net">Project Summary</a></li>
    <li><a href="http://sourceforge.net/projects/shark-project/files/">Downloads</a></li>
    <li><a href="http://sourceforge.net/projects/shark-project/develop">Subversion Repository</a></li>
  </ul>
  
</li>
<li class="first"><a href="../GettingStarted.html">Getting Started</a>
<li class="first"><a href="../Tutorials.html">Tutorials</a>
<li class="first"><a href="../FAQ.html">FAQ</a>

<li class="first"><a href="#">Main Modules</a>
<ul>
  <li class="first"><a href="../ReClaM/index.html">ReClaM</a>
  <li class="first"><a href="../EALib/index.html">EALib</a>
  <li class="first"><a href="../MOO-EALib/index.html">MOO-EALib</a>
  <li class="first"><a href="../Fuzzy/index.html">Fuzzy</a>
</ul>
</li>
<li class="first"><a href="#">Tools</a>
<ul>
  <li class="first"><a href="../Mixture/index.html">Mixture</a>
  <li><a href="../Array/index.html">Array</a>
  <li><a href="../Rng/index.html">Rng</a>
  <li><a href="../LinAlg/index.html">LinAlg</a>
  <li class="last"><a href="../FileUtil/index.html">FileUtil</a>		    
</ul>
</li>
</ul>
</div>

<!--<div id="header">
<div id="site-name">Shark Machine Learning Library</div>
  <ul id="nav">
    <li><a href="../index.html"><span>Shark&nbsp;Main&nbsp;Page</span></a></li>
    <li><a href="../Array/index.html"><span>Array</span></a></li>
    <li><a href="../Rng/index.html"><span>Rng</span></a></li>
    <li><a href="../LinAlg/index.html"><span>LinAlg</span></a></li>
    <li><a href="../FileUtil/index.html"><span>FileUtil</span></a></li>
    <li><a href="../EALib/index.html"><span>EALib</span></a></li>
    <li><a href="../MOO-EALib/index.html"><span>MOO-EALib</span></a></li>
    <li class="active"><a href="../ReClaM/index.html"><span>ReClaM</span></a></li>
    <li><a href="../Fuzzy/index.html"><span>Fuzzy</span></a></li>
    <li><a href="../Mixture/index.html"><span>Mixture</span></a></li>
    <li><a href="../tutorials/index.html"><span>Tutorials</span></a></li>
    <li><a href="../faq/index.html"><span>FAQ</span></a></li>
  </ul>
 </div> -->
<!-- Generated by Doxygen 1.7.3 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
    </ul>
  </div>
<div class="header">
  <div class="headertitle">
<h1>NoisySvmLikelihood.cpp</h1>  </div>
</div>
<div class="contents">
<a href="_noisy_svm_likelihood_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="comment">//===========================================================================</span>
<a name="l00041"></a>00041 <span class="comment"></span><span class="comment">//===========================================================================</span>
<a name="l00042"></a>00042 
<a name="l00043"></a>00043 
<a name="l00044"></a>00044 <span class="preprocessor">#include &lt;Rng/GlobalRng.h&gt;</span>
<a name="l00045"></a>00045 <span class="preprocessor">#include &lt;ReClaM/NoisySvmLikelihood.h&gt;</span>
<a name="l00046"></a>00046 <span class="preprocessor">#include &lt;ReClaM/Svm.h&gt;</span>
<a name="l00047"></a>00047 <span class="preprocessor">#include &lt;ReClaM/SigmoidModel.h&gt;</span>
<a name="l00048"></a>00048 <span class="preprocessor">#include &lt;ReClaM/NegativeLogLikelihood.h&gt;</span>
<a name="l00049"></a>00049 <span class="preprocessor">#include &lt;ReClaM/Rprop.h&gt;</span>
<a name="l00050"></a>00050 
<a name="l00051"></a>00051 <span class="preprocessor">#include &lt;vector&gt;</span>
<a name="l00052"></a>00052 <span class="preprocessor">#include &lt;algorithm&gt;</span>
<a name="l00053"></a>00053 
<a name="l00054"></a>00054 
<a name="l00055"></a>00055 <span class="comment">// choose exactly one of these:</span>
<a name="l00056"></a>00056 
<a name="l00057"></a>00057 <span class="comment">// exponential decaying sigmoid</span>
<a name="l00058"></a><a class="code" href="_noisy_svm_likelihood_8cpp.html#a04cefc299d9f583f8bf1476d12a4c288">00058</a> <span class="preprocessor">#define SIG_E</span>
<a name="l00059"></a>00059 <span class="preprocessor"></span>
<a name="l00060"></a>00060 <span class="comment">// polynomial decaying sigmoid</span>
<a name="l00061"></a>00061 <span class="comment">// #define SIG_P</span>
<a name="l00062"></a>00062 
<a name="l00063"></a>00063 
<a name="l00064"></a>00064 
<a name="l00066"></a>00066 
<a name="l00067"></a>00067 
<a name="l00068"></a><a class="code" href="class_noisy_svm_likelihood.html#ad15422347c0e7350f4ae66ad320a3af8">00068</a> <a class="code" href="class_noisy_svm_likelihood.html#ad15422347c0e7350f4ae66ad320a3af8" title="Constructor.">NoisySvmLikelihood::NoisySvmLikelihood</a>(<span class="keywordtype">double</span> trainFraction)
<a name="l00069"></a>00069 {
<a name="l00070"></a>00070     RANGE_CHECK(trainFraction &gt; 0.0 &amp;&amp; trainFraction &lt; 1.0);
<a name="l00071"></a>00071 
<a name="l00072"></a>00072     this-&gt;trainFraction = <a class="code" href="class_noisy_svm_likelihood.html#a1d4508fff7287bb7b447baf28898989c" title="fraction of the data used for training">trainFraction</a>;
<a name="l00073"></a>00073 }
<a name="l00074"></a>00074 
<a name="l00075"></a><a class="code" href="class_noisy_svm_likelihood.html#a2e6338ddd72a39d729a1599c021f1ac8">00075</a> <a class="code" href="class_noisy_svm_likelihood.html#a2e6338ddd72a39d729a1599c021f1ac8" title="Destructor.">NoisySvmLikelihood::~NoisySvmLikelihood</a>()
<a name="l00076"></a>00076 {
<a name="l00077"></a>00077 }
<a name="l00078"></a>00078 
<a name="l00079"></a>00079 
<a name="l00080"></a><a class="code" href="class_noisy_svm_likelihood.html#a4cbf6cbe582daca5cd9672c3dd45c0a3">00080</a> <span class="keywordtype">double</span> <a class="code" href="class_noisy_svm_likelihood.html#a4cbf6cbe582daca5cd9672c3dd45c0a3" title="computation of the negative log likelihood">NoisySvmLikelihood::error</a>(<a class="code" href="class_model.html" title="Base class of all models.">Model</a>&amp; model, <span class="keyword">const</span> Array&lt;double&gt;&amp; input, <span class="keyword">const</span> Array&lt;double&gt;&amp; target)
<a name="l00081"></a>00081 {
<a name="l00082"></a>00082     SIZE_CHECK(input.ndim() == 2);
<a name="l00083"></a>00083     SIZE_CHECK(target.ndim() == 2);
<a name="l00084"></a>00084 
<a name="l00085"></a>00085     <span class="comment">// check the model type</span>
<a name="l00086"></a>00086     <a class="code" href="class_c___s_v_m.html" title="Meta Model for SVM training.">C_SVM</a>* csvm = <span class="keyword">dynamic_cast&lt;</span><a class="code" href="class_c___s_v_m.html" title="Meta Model for SVM training.">C_SVM</a>*<span class="keyword">&gt;</span>(&amp;model);
<a name="l00087"></a>00087     <span class="keywordflow">if</span> (csvm == NULL || csvm-&gt;is2norm()) <span class="keywordflow">throw</span> SHARKEXCEPTION(<span class="stringliteral">&quot;[NoisySvmLikelihood::error] model must be a 1-norm C-SVM.&quot;</span>);
<a name="l00088"></a>00088 
<a name="l00089"></a>00089     <span class="comment">// randomly split the data</span>
<a name="l00090"></a>00090     <span class="keywordtype">int</span> <a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>, ic = input.dim(0);
<a name="l00091"></a>00091     <span class="keywordtype">int</span> dim = input.dim(1);
<a name="l00092"></a>00092     <span class="keywordtype">int</span> train_c = (int)(<a class="code" href="class_noisy_svm_likelihood.html#a1d4508fff7287bb7b447baf28898989c" title="fraction of the data used for training">trainFraction</a> * ic);
<a name="l00093"></a>00093     <span class="keywordtype">int</span> test_c = ic - train_c;
<a name="l00094"></a>00094     SIZE_CHECK(train_c &gt; 0 &amp;&amp; test_c &gt; 0);
<a name="l00095"></a>00095     Array&lt;double&gt; train_d(train_c, dim);
<a name="l00096"></a>00096     Array&lt;double&gt; train_l(train_c, 1);
<a name="l00097"></a>00097     Array&lt;double&gt; test_d(test_c, dim);
<a name="l00098"></a>00098     Array&lt;double&gt; test_l(test_c, 1);
<a name="l00099"></a>00099     std::vector&lt;int&gt; permutation(ic);
<a name="l00100"></a>00100     <span class="keywordflow">for</span> (i=0; i&lt;ic; i++) permutation[i] = i;
<a name="l00101"></a>00101     <span class="keywordflow">for</span> (i=0; i&lt;ic; i++)
<a name="l00102"></a>00102     {
<a name="l00103"></a>00103         <span class="keywordtype">int</span> j = Rng::discrete(0, ic-1);
<a name="l00104"></a>00104         <span class="keywordtype">int</span> tmp = permutation[j];
<a name="l00105"></a>00105         permutation[j] = permutation[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>];
<a name="l00106"></a>00106         permutation[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>] = tmp;
<a name="l00107"></a>00107     }
<a name="l00108"></a>00108     <span class="keywordflow">for</span> (i=0; i&lt;train_c; i++)
<a name="l00109"></a>00109     {
<a name="l00110"></a>00110         train_d[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>] = input[permutation[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>]];
<a name="l00111"></a>00111         train_l[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>] = target[permutation[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>]];
<a name="l00112"></a>00112     }
<a name="l00113"></a>00113     <span class="keywordflow">for</span> (i=0; i&lt;test_c; i++)
<a name="l00114"></a>00114     {
<a name="l00115"></a>00115         test_d[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>] = input[permutation[train_c + <a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>]];
<a name="l00116"></a>00116         test_l[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>] = target[permutation[train_c + <a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>]];
<a name="l00117"></a>00117     }
<a name="l00118"></a>00118 
<a name="l00119"></a>00119     <span class="comment">// train the SVM</span>
<a name="l00120"></a>00120     <a class="code" href="class_s_v_m.html" title="Support Vector Machine (SVM) as a ReClaM Model.">SVM</a>* svm = csvm-&gt;getSVM();
<a name="l00121"></a>00121     <a class="code" href="class_s_v_m___optimizer.html" title="Optimizer for SVM training by quadratic programming.">SVM_Optimizer</a> opt;
<a name="l00122"></a>00122     opt.<a class="code" href="class_s_v_m___optimizer.html#aa5800eac30b1157d516f232260cd0c25" title="Default initialization.">init</a>(*csvm);
<a name="l00123"></a>00123     opt.<a class="code" href="class_s_v_m___optimizer.html#abad3f5a564fac9bcbfe7e753bf2f4655" title="Default Optimizer interface.">optimize</a>(*svm, train_d, train_l);
<a name="l00124"></a>00124 
<a name="l00125"></a>00125     <span class="comment">// predict the validation data</span>
<a name="l00126"></a>00126     Array&lt;double&gt; z(test_c, 1);
<a name="l00127"></a>00127     svm-&gt;<a class="code" href="class_s_v_m.html#ac7f7ac27c5eab27c8f59b495f6e2c9f5" title="compute the SVM prediction on data">model</a>(test_d, z);
<a name="l00128"></a>00128 
<a name="l00129"></a>00129     <span class="comment">// train a sigmoid on the validation data</span>
<a name="l00130"></a>00130 <span class="preprocessor">#ifdef SIG_E</span>
<a name="l00131"></a>00131 <span class="preprocessor"></span>    <a class="code" href="class_sigmoid_model.html" title="Standard sigmoid function with two parameters.">SigmoidModel</a> sigmoid;
<a name="l00132"></a>00132 <span class="preprocessor">#endif</span>
<a name="l00133"></a>00133 <span class="preprocessor"></span><span class="preprocessor">#ifdef SIG_P</span>
<a name="l00134"></a>00134 <span class="preprocessor"></span>    <a class="code" href="class_simple_sigmoid_model.html" title="Simple sigmoid function with one parameter.">SimpleSigmoidModel</a> sigmoid;
<a name="l00135"></a>00135 <span class="preprocessor">#endif</span>
<a name="l00136"></a>00136 <span class="preprocessor"></span>    <a class="code" href="class_negative_log_likelihood.html" title="negative logarithm of the likelihood of a probabilistic binary classification model">NegativeLogLikelihood</a> nll;
<a name="l00137"></a>00137     <a class="code" href="class_i_rprop_plus.html" title="This class offers methods for the usage of the improved Resilient-Backpropagation-algorithm with weig...">IRpropPlus</a> rprop;
<a name="l00138"></a>00138     rprop.<a class="code" href="class_i_rprop_plus.html#a1200d6b247139bf76b20a9d49768d639" title="Initializes the optimizer with default parameters.">init</a>(sigmoid);
<a name="l00139"></a>00139     <span class="keywordflow">for</span> (i=0; i&lt;100; i++)
<a name="l00140"></a>00140     {
<a name="l00141"></a>00141         rprop.<a class="code" href="class_i_rprop_plus.html#af67f44cd73418c5e083fc57704341855" title="Performs a run of the Rprop algorithm.">optimize</a>(sigmoid, nll, z, test_l);
<a name="l00142"></a>00142 <span class="preprocessor">#ifdef SIG_E</span>
<a name="l00143"></a>00143 <span class="preprocessor"></span>        sigmoid.<a class="code" href="class_model.html#a7eac39377437bd4f0f9c6368e6cbe6f4" title="Modifies a specific model parameter.">setParameter</a>(1, 0.0);
<a name="l00144"></a>00144         <span class="keywordflow">if</span> (sigmoid.<a class="code" href="class_model.html#a8e8eca8ae3e8e53ca0aa6a1731e1f0f6" title="Returns a specific model parameter.">getParameter</a>(0) &gt; 0.0) sigmoid.<a class="code" href="class_model.html#a7eac39377437bd4f0f9c6368e6cbe6f4" title="Modifies a specific model parameter.">setParameter</a>(0, 0.0);
<a name="l00145"></a>00145 <span class="preprocessor">#endif</span>
<a name="l00146"></a>00146 <span class="preprocessor"></span><span class="preprocessor">#ifdef SIG_P</span>
<a name="l00147"></a>00147 <span class="preprocessor"></span>        <span class="keywordflow">if</span> (sigmoid.<a class="code" href="class_model.html#a8e8eca8ae3e8e53ca0aa6a1731e1f0f6" title="Returns a specific model parameter.">getParameter</a>(0) &lt; 0.0) sigmoid.<a class="code" href="class_model.html#a7eac39377437bd4f0f9c6368e6cbe6f4" title="Modifies a specific model parameter.">setParameter</a>(0, 0.0);
<a name="l00148"></a>00148 <span class="preprocessor">#endif</span>
<a name="l00149"></a>00149 <span class="preprocessor"></span>    }
<a name="l00150"></a>00150 
<a name="l00151"></a>00151     <span class="comment">// return the best negative log likelihood</span>
<a name="l00152"></a>00152     <span class="keywordflow">return</span> nll.<a class="code" href="class_negative_log_likelihood.html#acfd7f88411716c14c51e5af686e996eb" title="error computation, see class description">error</a>(sigmoid, z, test_l);
<a name="l00153"></a>00153 }
<a name="l00154"></a>00154 
<a name="l00155"></a><a class="code" href="class_noisy_svm_likelihood.html#af23c14b90e1a3834523afb2e06a0964e">00155</a> <span class="keywordtype">double</span> <a class="code" href="class_noisy_svm_likelihood.html#af23c14b90e1a3834523afb2e06a0964e" title="computation of the negative log likelihood and its derivatives w.r.t.">NoisySvmLikelihood::errorDerivative</a>(<a class="code" href="class_model.html" title="Base class of all models.">Model</a>&amp; model, <span class="keyword">const</span> Array&lt;double&gt;&amp; input, <span class="keyword">const</span> Array&lt;double&gt;&amp; target, Array&lt;double&gt;&amp; derivative)
<a name="l00156"></a>00156 {
<a name="l00157"></a>00157     SIZE_CHECK(input.ndim() == 2);
<a name="l00158"></a>00158     SIZE_CHECK(target.ndim() == 2);
<a name="l00159"></a>00159 
<a name="l00160"></a>00160     <span class="comment">// check the model type</span>
<a name="l00161"></a>00161     <a class="code" href="class_c___s_v_m.html" title="Meta Model for SVM training.">C_SVM</a>* csvm = <span class="keyword">dynamic_cast&lt;</span><a class="code" href="class_c___s_v_m.html" title="Meta Model for SVM training.">C_SVM</a>*<span class="keyword">&gt;</span>(&amp;model);
<a name="l00162"></a>00162     <span class="keywordflow">if</span> (csvm == NULL || csvm-&gt;is2norm()) <span class="keywordflow">throw</span> SHARKEXCEPTION(<span class="stringliteral">&quot;[NoisySvmLikelihood::errorDerivative] model must be a 1-norm C-SVM.&quot;</span>);
<a name="l00163"></a>00163 
<a name="l00164"></a>00164     <span class="comment">// randomly split the data</span>
<a name="l00165"></a>00165     <span class="keywordtype">int</span> <a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>, ic = input.dim(0);
<a name="l00166"></a>00166     <span class="keywordtype">int</span> dim = input.dim(1);
<a name="l00167"></a>00167     <span class="keywordtype">int</span> train_c = (int)(<a class="code" href="class_noisy_svm_likelihood.html#a1d4508fff7287bb7b447baf28898989c" title="fraction of the data used for training">trainFraction</a> * ic);
<a name="l00168"></a>00168     <span class="keywordtype">int</span> test_c = ic - train_c;
<a name="l00169"></a>00169     SIZE_CHECK(train_c &gt; 0 &amp;&amp; test_c &gt; 0);
<a name="l00170"></a>00170     Array&lt;double&gt; train_d(train_c, dim);
<a name="l00171"></a>00171     Array&lt;double&gt; train_l(train_c, 1);
<a name="l00172"></a>00172     Array&lt;double&gt; test_d(test_c, dim);
<a name="l00173"></a>00173     Array&lt;double&gt; test_l(test_c, 1);
<a name="l00174"></a>00174     std::vector&lt;int&gt; permutation(ic);
<a name="l00175"></a>00175     <span class="keywordflow">for</span> (i=0; i&lt;ic; i++) permutation[i] = i;
<a name="l00176"></a>00176     <span class="keywordflow">for</span> (i=0; i&lt;ic; i++)
<a name="l00177"></a>00177     {
<a name="l00178"></a>00178         <span class="keywordtype">int</span> j = Rng::discrete(0, ic-1);
<a name="l00179"></a>00179         <span class="keywordtype">int</span> tmp = permutation[j];
<a name="l00180"></a>00180         permutation[j] = permutation[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>];
<a name="l00181"></a>00181         permutation[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>] = tmp;
<a name="l00182"></a>00182     }
<a name="l00183"></a>00183     <span class="keywordflow">for</span> (i=0; i&lt;train_c; i++)
<a name="l00184"></a>00184     {
<a name="l00185"></a>00185         train_d[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>] = input[permutation[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>]];
<a name="l00186"></a>00186         train_l[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>] = target[permutation[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>]];
<a name="l00187"></a>00187     }
<a name="l00188"></a>00188     <span class="keywordflow">for</span> (i=0; i&lt;test_c; i++)
<a name="l00189"></a>00189     {
<a name="l00190"></a>00190         test_d[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>] = input[permutation[train_c + <a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>]];
<a name="l00191"></a>00191         test_l[<a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>] = target[permutation[train_c + <a class="code" href="_b_f_g_s_8cpp.html#ac23062089f3a5a2693cbb4ce7a75f1e5" title="Initializes some internal variables used by the BFGS algorithm, calculates the current error of the m...">i</a>]];
<a name="l00192"></a>00192     }
<a name="l00193"></a>00193 
<a name="l00194"></a>00194     <span class="comment">// train the SVM</span>
<a name="l00195"></a>00195     <a class="code" href="class_s_v_m.html" title="Support Vector Machine (SVM) as a ReClaM Model.">SVM</a>* svm = csvm-&gt;getSVM();
<a name="l00196"></a>00196     <a class="code" href="class_s_v_m___optimizer.html" title="Optimizer for SVM training by quadratic programming.">SVM_Optimizer</a> opt;
<a name="l00197"></a>00197     opt.<a class="code" href="class_s_v_m___optimizer.html#aa5800eac30b1157d516f232260cd0c25" title="Default initialization.">init</a>(*csvm);
<a name="l00198"></a>00198     opt.<a class="code" href="class_s_v_m___optimizer.html#abad3f5a564fac9bcbfe7e753bf2f4655" title="Default Optimizer interface.">optimize</a>(*svm, train_d, train_l);
<a name="l00199"></a>00199 
<a name="l00200"></a>00200     <span class="comment">// predict the validation data</span>
<a name="l00201"></a>00201     Array&lt;double&gt; z(test_c, 1);
<a name="l00202"></a>00202     svm-&gt;<a class="code" href="class_s_v_m.html#ac7f7ac27c5eab27c8f59b495f6e2c9f5" title="compute the SVM prediction on data">model</a>(test_d, z);
<a name="l00203"></a>00203 
<a name="l00204"></a>00204     <span class="comment">// train a sigmoid on the validation data</span>
<a name="l00205"></a>00205 <span class="preprocessor">#ifdef SIG_E</span>
<a name="l00206"></a>00206 <span class="preprocessor"></span>    <a class="code" href="class_sigmoid_model.html" title="Standard sigmoid function with two parameters.">SigmoidModel</a> sigmoid;
<a name="l00207"></a>00207 <span class="preprocessor">#endif</span>
<a name="l00208"></a>00208 <span class="preprocessor"></span><span class="preprocessor">#ifdef SIG_P</span>
<a name="l00209"></a>00209 <span class="preprocessor"></span>    <a class="code" href="class_simple_sigmoid_model.html" title="Simple sigmoid function with one parameter.">SimpleSigmoidModel</a> sigmoid;
<a name="l00210"></a>00210 <span class="preprocessor">#endif</span>
<a name="l00211"></a>00211 <span class="preprocessor"></span>    <a class="code" href="class_negative_log_likelihood.html" title="negative logarithm of the likelihood of a probabilistic binary classification model">NegativeLogLikelihood</a> nll;
<a name="l00212"></a>00212     <a class="code" href="class_i_rprop_plus.html" title="This class offers methods for the usage of the improved Resilient-Backpropagation-algorithm with weig...">IRpropPlus</a> rprop;
<a name="l00213"></a>00213     rprop.<a class="code" href="class_i_rprop_plus.html#a1200d6b247139bf76b20a9d49768d639" title="Initializes the optimizer with default parameters.">init</a>(sigmoid);
<a name="l00214"></a>00214     <span class="keywordflow">for</span> (i=0; i&lt;100; i++)
<a name="l00215"></a>00215     {
<a name="l00216"></a>00216         rprop.<a class="code" href="class_i_rprop_plus.html#af67f44cd73418c5e083fc57704341855" title="Performs a run of the Rprop algorithm.">optimize</a>(sigmoid, nll, z, test_l);
<a name="l00217"></a>00217 <span class="preprocessor">#ifdef SIG_E</span>
<a name="l00218"></a>00218 <span class="preprocessor"></span>        sigmoid.<a class="code" href="class_model.html#a7eac39377437bd4f0f9c6368e6cbe6f4" title="Modifies a specific model parameter.">setParameter</a>(1, 0.0);
<a name="l00219"></a>00219         <span class="keywordflow">if</span> (sigmoid.<a class="code" href="class_model.html#a8e8eca8ae3e8e53ca0aa6a1731e1f0f6" title="Returns a specific model parameter.">getParameter</a>(0) &gt; 0.0) sigmoid.<a class="code" href="class_model.html#a7eac39377437bd4f0f9c6368e6cbe6f4" title="Modifies a specific model parameter.">setParameter</a>(0, 0.0);
<a name="l00220"></a>00220 <span class="preprocessor">#endif</span>
<a name="l00221"></a>00221 <span class="preprocessor"></span><span class="preprocessor">#ifdef SIG_P</span>
<a name="l00222"></a>00222 <span class="preprocessor"></span>        <span class="keywordflow">if</span> (sigmoid.<a class="code" href="class_model.html#a8e8eca8ae3e8e53ca0aa6a1731e1f0f6" title="Returns a specific model parameter.">getParameter</a>(0) &lt; 0.0) sigmoid.<a class="code" href="class_model.html#a7eac39377437bd4f0f9c6368e6cbe6f4" title="Modifies a specific model parameter.">setParameter</a>(0, 0.0);
<a name="l00223"></a>00223 <span class="preprocessor">#endif</span>
<a name="l00224"></a>00224 <span class="preprocessor"></span>    }
<a name="l00225"></a>00225 
<a name="l00226"></a>00226     <span class="comment">// compute the derivative</span>
<a name="l00227"></a>00227     Array&lt;double&gt; p(test_c, 1);
<a name="l00228"></a>00228     sigmoid.<a class="code" href="class_simple_sigmoid_model.html#aa9dae0e3cbe874571d488cf0504f3837" title="apply the model">model</a>(z, p);
<a name="l00229"></a>00229 
<a name="l00230"></a>00230     <span class="keywordtype">int</span> b, bc = csvm-&gt;getParameterDimension();
<a name="l00231"></a>00231     derivative.resize(bc, <span class="keyword">false</span>);
<a name="l00232"></a>00232     derivative = 0.0;
<a name="l00233"></a>00233     Array&lt;double&gt; dz_dtheta;
<a name="l00234"></a>00234     csvm-&gt;PrepareDerivative();
<a name="l00235"></a>00235     <span class="keywordflow">for</span> (i=0; i&lt;test_c; i++)
<a name="l00236"></a>00236     {
<a name="l00237"></a>00237         <span class="comment">// compute the derivative of the negative log likelihood</span>
<a name="l00238"></a>00238         <span class="keywordtype">double</span> dL_dp;
<a name="l00239"></a>00239         <span class="keywordflow">if</span> (test_l(i, 0) &gt; 0.0) dL_dp = -1.0 / p(i, 0);
<a name="l00240"></a>00240         <span class="keywordflow">else</span> dL_dp = -1.0 / (p(i, 0) - 1.0);
<a name="l00241"></a>00241 
<a name="l00242"></a>00242         <span class="comment">// compute the derivative of the sigmoid</span>
<a name="l00243"></a>00243 <span class="preprocessor">#ifdef SIG_E</span>
<a name="l00244"></a>00244 <span class="preprocessor"></span>        <span class="keywordtype">double</span> dp_dz = - sigmoid.<a class="code" href="class_model.html#a8e8eca8ae3e8e53ca0aa6a1731e1f0f6" title="Returns a specific model parameter.">getParameter</a>(0) * p(i, 0) * (1.0 - p(i, 0));
<a name="l00245"></a>00245 <span class="preprocessor">#endif</span>
<a name="l00246"></a>00246 <span class="preprocessor"></span><span class="preprocessor">#ifdef SIG_P</span>
<a name="l00247"></a>00247 <span class="preprocessor"></span>        <span class="keywordtype">double</span> x = sigmoid.<a class="code" href="class_model.html#a8e8eca8ae3e8e53ca0aa6a1731e1f0f6" title="Returns a specific model parameter.">getParameter</a>(0) * p(i, 0);
<a name="l00248"></a>00248         <span class="keywordtype">double</span> N = 1.0 + fabs(x);
<a name="l00249"></a>00249         <span class="keywordtype">double</span> dp_dz = sigmoid.<a class="code" href="class_model.html#a8e8eca8ae3e8e53ca0aa6a1731e1f0f6" title="Returns a specific model parameter.">getParameter</a>(0) / (N * N);
<a name="l00250"></a>00250 <span class="preprocessor">#endif</span>
<a name="l00251"></a>00251 <span class="preprocessor"></span>
<a name="l00252"></a>00252         <span class="comment">// compute the derivative of the SVM</span>
<a name="l00253"></a>00253         csvm-&gt;modelDerivative(test_d[i], dz_dtheta);
<a name="l00254"></a>00254 
<a name="l00255"></a>00255         <span class="comment">// total derivative = partial derivative</span>
<a name="l00256"></a>00256         <span class="keywordflow">for</span> (b=0; b&lt;bc; b++) derivative(b) += dL_dp * dp_dz * dz_dtheta(0, b);
<a name="l00257"></a>00257     }
<a name="l00258"></a>00258 
<a name="l00259"></a>00259     <span class="comment">// return the best negative log likelihood</span>
<a name="l00260"></a>00260     <span class="keywordflow">return</span> nll.<a class="code" href="class_negative_log_likelihood.html#acfd7f88411716c14c51e5af686e996eb" title="error computation, see class description">error</a>(sigmoid, z, test_l);
<a name="l00261"></a>00261 }
</pre></div></div>
</div>
</div>
</div>
</body></html>
