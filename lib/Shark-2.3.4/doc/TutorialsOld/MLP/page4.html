<html>

<head>
	<link type="text/css" rel="stylesheet" href="../content.css">
</head>

<body>

<h1>Defining a Learning Algorithm</h1>

<p>
	We want to train the neural network using a gradient-based
	optimization algorithm.  The optimizer requires initialization based
	on the model.
</p>
<pre><div class="code">#include &lt;Array/Array.h&gt;
#include &lt;ReClaM/FFNet.h&gt;
#include &lt;ReClaM/createConnectionMatrix.h&gt;
#include &lt;ReClaM/CrossEntropy.h&gt;<div class="newcode">#include &lt;ReClaM/Rprop.h&gt;</div>
int main()
{
  // just index variables
  unsigned i, j, k, t;
	
  // construct xor problem
  Array&lt;double&gt; trainInput(4, 2);
  Array&lt;double&gt; trainTarget(4, 1);
  for(k=0, i=0; i<2; i++) {
    for(j=0; j<2; j++) {
      trainInput(k, 0) = i;
      trainInput(k, 1) = j;
      trainTarget(k, 0) = (i+j) % 2;
      k++;
    }
  }
  // define topology
  unsigned inputs = 2;
  unsigned hidden = 2;
  unsigned outputs = 1;

  // create connection matrix 
  Array&lt;int&gt; con;
  createConnectionMatrix(con, 
                         inputs, hidden, outputs);

  // feed-forward neural network
  FFNet net(inputs, outputs, con);
  // error function
  CrossEntropy error;
<div class="newcode">
  // optimizer
  IRpropPlus optimizer;
  optimizer.init(net);
</div>
  return EXIT_SUCCESS;
}
</div></pre>
<p>
	Our default choice for gradient-base optimization is the improved Rprop
	algorithm with backtracking, an efficient and robust first-order
	method (see reference below for details). However, there a plenty 
	of other learning algorithms available in Shark (e.g., steepest descent,
	Quickprop, BFGS, conjugate gradient algorithm)
</p>

<div class=publication>Christian Igel and Michael  H&uuml;sken.
<a target="_blank"> href="http://www.neuroinformatik.ruhr-uni-bochum.de/ini/PEOPLE/igel/EEotIRLA.ps.gz">Empirical Evaluation of the Improved Rprop Learning Algorithm</a>.
<em>Neurocomputing</em> <vol>50</vol>(C), pp. 105-123, 2003</div>

</body>

</html>
