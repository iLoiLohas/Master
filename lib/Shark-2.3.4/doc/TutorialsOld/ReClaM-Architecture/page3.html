<html>

<head>
	<link type="text/css" rel="stylesheet" href="../content.css">
</head>

<body>

<h1>Linear Regression</h1>
<p>
	Although we know that our data are not linear (they are quadratic)
	in nature we can still search for the best linear fit. This task is
	usually realized with the <tt>LinearRegression</tt> class in ReClaM, but you
	will learn a lot more about how ReClaM works if we ignore this class
	for a moment and try to find the solution with different tools. Of
	course, the <tt>LinearRegression</tt> class solves the problem in closed
	form, but recall that linear regression minimizes the mean squared
	error of an affine linear fit. That is, we should use an affine
	linear function as our underlying model and the mean squared error
	as the error function to minimize. Then we can iteratively adapt the
	model parameters to approximate the optimal fit with the improved
	Rprop algorithm. In fact, the classes <tt>AffineLinearMap</tt>,
	<tt>MeanSquaredError</tt> and <tt>IRpropPlus</tt> are subclasses of the ReClaM base
	classes <tt>Model</tt>, <tt>ErrorFunction</tt> and <tt>Optimizer</tt>, respectively.
</p>

<pre><div class="code">#include &lt;iostream&gt;
#include &lt;Rng/GlobalRng.h&gt;
#include &lt;ReClaM/Dataset.h&gt;
<div class="newcode">#include &lt;ReClaM/LinearModel.h&gt;
#include &lt;ReClaM/MeanSquaredError.h&gt;
#include &lt;ReClaM/Rprop.h&gt;
</div>
class MyProblem : public DataSource
{
public:
    MyProblem()
    {
        dataDim = 1;
        targetDim = 1;
    }

    bool GetData(Array&lt;double&gt;&amp; data, Array&lt;double&gt;&amp; target, int count)
    {
        data.resize(count, 1, false);
        target.resize(count, 1, false);
        int i;
        for (i=0; i&lt;count; i++)
        {
            double x = Rng::uni(0.0, 1.0);
            double y = x * x + Rng::gauss(0.0, 0.01);
            data(i, 0) = x;
            target(i, 0) = y;
        }
        return true;
    }
};

int main(int argc, char** argv)
{
    MyProblem problem;
    Dataset dataset(problem, 100, 1000);
<div class="newcode">
    AffineLinearMap     model(1, 1);      // 1-dim. input and output
    MeanSquaredError    mse;
    IRpropPlus optimizer;

    int iter;
    optimizer.init(model);
    for (iter=0; iter&lt;100; iter++)
    {
        optimizer.optimize(model, mse, dataset.getTrainingData(),
                                       dataset.getTrainingTarget());
    }</div>}
</div></pre>

<p>
	The iterative gradient based Rprop optimization strategy is called 100
	times to improve the parameters of the model, hopefully resulting in an
	acceptable fit. To assess the quality of the fit we compute the mean
	squared error on the test data:
</p>
<pre><div class="code">    double e = mse.error(model, dataset.getTestData(),
                                dataset.getTestTarget());
    std::cout &lt;&lt; &quot;test MSE: &quot; &lt;&lt; e &lt;&lt; std::endl;
</div></pre>

<p>
	This program outputs a mean squared error value of about 0.016.
</p>

</body>

</html>
