<html>

<head>
	<link type="text/css" rel="stylesheet" href="../content.css">
</head>

<body>

<h1>Performance Test</h1>

<p>
	We use the 1000 test examples to estimate the generalization
	error of the resulting machine. The winner-takes-all (WTA) error
	function computes the fraction of misclassified examples using
	the LDA label representation.
</p>

<pre><div class="code">#include &lt;Rng/GlobalRng.h&gt;
#include &lt;ReClaM/Dataset.h&gt;
#include &lt;ReClaM/LinearModel.h&gt;
#include &lt;ReClaM/LDA.h&gt;
<div class="newcode">#include &lt;ReClaM/WTA.h&gt;</div>

class MultiClassProblem : public DataSource
{
public:
    MultiClassProblem()
    {
        dataDim = 2;
        targetDim = 3;
    }

    bool GetData(Array&lt;double&gt;&amp; data, Array&lt;double&gt;&amp; target, int count)
    {
        data.resize(count, 2, false);
        target.resize(count, 3, false);
        target = 0.0;
        int i, c;
        for (i=0; i&lt;count; i++)
        {
            c = Rng::discrete(0, 2);
            data(i, 1) = 0.7 * Rng::gauss();
            data(i, 0) = 0.7 * Rng::gauss() - 1.0 * data(i, 1);
            if (c == 0) data(i, 0) -= 1.0;
            else if (c == 1) data(i, 1) += 2.0;
            else if (c == 2) data(i, 0) += 1.0;
            target(i, c) = 1.0;
        }
        return true;
    }
};

int main(int argc, char** argv)
{
    MultiClassProblem problem;
    Dataset dataset(problem, 100, 1000);

    LinearClassifier model(2, 3);
    LDA optimizer;
    optimizer.init(model);
    optimizer.optimize(model, dataset.getTrainingData(),
                              dataset.getTrainingTarget());
<div class="newcode">
    WTA err;
    double e = err.error(model, dataset.getTestData(),
                                dataset.getTestTarget());
    std::cout &lt;&lt; "fraction of errors: " &lt;&lt; e &lt;&lt; std::endl;</div>}
</div></pre>

<p>
	After training of the LDA classifier the program computes and
	outputs the test error.
</p>

<div class="shell">fraction of errors: 0.081</div>

</body>

</html>
