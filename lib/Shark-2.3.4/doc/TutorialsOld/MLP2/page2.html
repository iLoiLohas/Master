<html>

<head>
	<link type="text/css" rel="stylesheet" href="../content.css">
</head>

<body>

<h1>Defining a New Network Class</h1>

We want to solve the regression problem with a network with linear
output neurons. The transfer functions of the hidden neurons should
be the hyperbolic tangent function.

<p>First, we define our own network class, which inherits from
the class FFNet.h.

<div class="code">#include &lt;ReClaM/FFNet.h>

class MyNet : public FFNet {
public:
  MyNet(unsigned i, unsigned o, const Array&lt;int> c) : FFNet(i, o, c) {};
};
</div>
<p>
Because we are lazy, we added only one constructor, which builds the network
given the number of inputs, the number of outputs, and a connection matrix.
</p>

<p>ReClaM allows to choose arbitrary transfer functions for output and
hidden neurons. We now overload the transfer function for the hidden
neurons, which is called <tt>g</tt>, to be the tanh:

<div class="code">#include &lt;ReClaM/FFNet.h&gt;

class MyNet : public FFNet {
public:
  MyNet(unsigned i, unsigned o, const Array&lt;int&gt; c) : FFNet(i, o, c) {};
<div class="newcode">  double g(double a) {
    return tanh(a);
  }</div>};
</div>
</p>

<p>
But this is not enough, we have to teach the new network class the
derivative of this transfer function. More precisely, we have to overload the function <tt>dg</tt>, which computes the derivative of 
 <tt>g(x)</tt> with respect to <tt>x</tt> given <tt>g(x)</tt> (not
given <tt>x</tt>!). Thus, we have:

<div class="code">#include &lt;ReClaM/FFNet.h&gt;

class MyNet : public FFNet {
public:
  MyNet(unsigned i, unsigned o, const Array&lt;int&gt; c) : FFNet(i, o, c) {};
  double g(double a) {
    return tanh(a);
  }<div class="newcode">  double dg(double ga) {
    return 1 - ga * ga;
  }</div>};
</div>
</p>

<p>Changing the transfer functions of the output nodes works
similar by overloading the functions 
<tt>dgOutput</tt> and <tt>dgOutput</tt>. For linear output 
neurons, we have:
<div class="code">#include &lt;ReClaM/FFNet.h&gt;

class MyNet : public FFNet {
public:
  MyNet(unsigned i, unsigned o, const Array&lt;int> c) : FFNet(i, o, c) {};
  double g(double a) {
    return tanh(a);
  }
  double dg(double ga) {
    return 1 - ga * ga;
  }<div class="newcode">  double gOutput(double a) {
    return a;
  }double dgOutput(double ga) {
    return 1.;
  }</div>};
</div>
</p>

<p>Now we instantiate 
out new neural network class with a network having a single input, a single output, and two hidden layers with three and two neurons, respectively.

<div class="code">#include &lt;ReClaM/FFNet.h><div class="newcode">#include &lt;ReClaM/createConnectionMatrix.h></div>
class MyNet : public FFNet {
public:
  MyNet(unsigned i, unsigned o, const Array&lt;int&gt; c) : FFNet(i, o, c) {};
  double g(double a) {
    return tanh(a);
  }
  double dg(double ga) {
    return 1 - ga * ga;
  }
  double gOutput(double a) {
    return a;
  }double dgOutput(double ga) {
    return 1.;
  }
};

int main()
{
  unsigned i, t; // just index variables
  double x, y;

  // construct sinc problem
  const unsigned numberTrainingPatterns = 50;
  Array&lt;double> trainInput (numberTrainingPatterns, 1);
  Array&lt;double> trainTarget(numberTrainingPatterns, 1);	
  Array&lt;double> valInput(numberValPatterns, 1);
  Array&lt;double> valTarget(numberValPatterns, 1);
  for(i=0; i&lt;numberTrainingPatterns; i++) {
    x = Rng::uni(-10., 10);
    y = sin(x)/x + Rng::gauss(0, 0.001);
    trainInput(i, 0)  = x;
    trainTarget(i, 0) = y;
    x = Rng::uni(-10., 10);
    y = sin(x)/x;
    valInput(i, 0)  = x;
    valTarget(i, 0) = y;
  } 

<div class="newcode">  // define topology unsigned 
  unsigned inputs = 1; 
  unsigned firstHiddenLayer = 3; 
  unsigned secondHiddenLayer = 2; 
  unsigned outputs = 1;

  Array&lt;int&gt; con;
  createConnectionMatrix(con, inputs, 
                         firstHiddenLayer, secondHiddenLayer, outputs);

  // feed-forward neural network
  MyNet net(inputs, outputs, con);</div>
  return EXIT_SUCCESS;
}
</div>
</p>

</body>

</html>
